{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-d7472da2d478>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Suraj\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Suraj\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\Suraj\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\Suraj\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Suraj\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Suraj\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = mnist.train.images[3].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images.shape)\n",
    "print(mnist.test.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20962938a48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 80\n",
    "epochs = 100\n",
    "\n",
    "n_hidden1 = 256\n",
    "n_hidden2 = 256\n",
    "n_input = 784\n",
    "n_output = 10\n",
    "n_samples = mnist.train.num_examples\n",
    "\n",
    "x = tf.placeholder('float',[None,n_input])\n",
    "y = tf.placeholder('float',[None,n_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "def model(x,weights,biases):\n",
    "    \n",
    "    layer1 = tf.add(tf.matmul(x,weights['w1']),bias['b1'])\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "\n",
    "    layer2 = tf.add(tf.matmul(layer1,weights['w2']),bias['b2'])\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "\n",
    "    out_layer = tf.add(tf.matmul(layer2,weights['w3']),bias['b3'])\n",
    "\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights and biases\n",
    "\n",
    "weights = {\n",
    "    'w1':tf.Variable(tf.random_normal([n_input,n_hidden1])),\n",
    "    'w2':tf.Variable(tf.random_normal([n_hidden1,n_hidden2])),\n",
    "    'w3':tf.Variable(tf.random_normal([n_hidden2,n_output]))    \n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden2])),\n",
    "    'b3':tf.Variable(tf.random_normal([n_output]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the predictions\n",
    "pred = model(x,weights,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cost and loss funcions\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=1989.6813\n",
      "Epoch: 2 cost=1324.4345\n",
      "Epoch: 3 cost=842.3131\n",
      "Epoch: 4 cost=672.9151\n",
      "Epoch: 5 cost=546.4086\n",
      "Epoch: 6 cost=449.8121\n",
      "Epoch: 7 cost=380.6813\n",
      "Epoch: 8 cost=360.7185\n",
      "Epoch: 9 cost=314.1312\n",
      "Epoch: 10 cost=246.9195\n",
      "Epoch: 11 cost=241.5810\n",
      "Epoch: 12 cost=241.4690\n",
      "Epoch: 13 cost=208.7967\n",
      "Epoch: 14 cost=203.8278\n",
      "Epoch: 15 cost=155.5891\n",
      "Epoch: 16 cost=164.3408\n",
      "Epoch: 17 cost=164.8613\n",
      "Epoch: 18 cost=155.7595\n",
      "Epoch: 19 cost=171.8364\n",
      "Epoch: 20 cost=157.6583\n",
      "Epoch: 21 cost=138.0911\n",
      "Epoch: 22 cost=151.7183\n",
      "Epoch: 23 cost=147.5645\n",
      "Epoch: 24 cost=129.9956\n",
      "Epoch: 25 cost=141.9283\n",
      "Epoch: 26 cost=121.2724\n",
      "Epoch: 27 cost=112.5383\n",
      "Epoch: 28 cost=105.2802\n",
      "Epoch: 29 cost=109.5118\n",
      "Epoch: 30 cost=114.9754\n",
      "Epoch: 31 cost=94.0470\n",
      "Epoch: 32 cost=102.4723\n",
      "Epoch: 33 cost=87.7198\n",
      "Epoch: 34 cost=96.7508\n",
      "Epoch: 35 cost=81.4044\n",
      "Epoch: 36 cost=102.0591\n",
      "Epoch: 37 cost=88.0315\n",
      "Epoch: 38 cost=80.2472\n",
      "Epoch: 39 cost=100.8144\n",
      "Epoch: 40 cost=90.2175\n",
      "Epoch: 41 cost=76.0027\n",
      "Epoch: 42 cost=75.9113\n",
      "Epoch: 43 cost=69.5764\n",
      "Epoch: 44 cost=93.8701\n",
      "Epoch: 45 cost=88.1786\n",
      "Epoch: 46 cost=70.7649\n",
      "Epoch: 47 cost=71.2507\n",
      "Epoch: 48 cost=73.1011\n",
      "Epoch: 49 cost=75.4143\n",
      "Epoch: 50 cost=75.3516\n",
      "Epoch: 51 cost=73.4941\n",
      "Epoch: 52 cost=66.2789\n",
      "Epoch: 53 cost=61.2738\n",
      "Epoch: 54 cost=71.1655\n",
      "Epoch: 55 cost=64.4100\n",
      "Epoch: 56 cost=67.7296\n",
      "Epoch: 57 cost=67.7939\n",
      "Epoch: 58 cost=57.5672\n",
      "Epoch: 59 cost=60.9760\n",
      "Epoch: 60 cost=71.0794\n",
      "Epoch: 61 cost=64.6827\n",
      "Epoch: 62 cost=60.5825\n",
      "Epoch: 63 cost=66.6470\n",
      "Epoch: 64 cost=51.3027\n",
      "Epoch: 65 cost=54.4022\n",
      "Epoch: 66 cost=58.9291\n",
      "Epoch: 67 cost=57.5656\n",
      "Epoch: 68 cost=54.6465\n",
      "Epoch: 69 cost=55.2677\n",
      "Epoch: 70 cost=59.0409\n",
      "Epoch: 71 cost=51.6288\n",
      "Epoch: 72 cost=41.5577\n",
      "Epoch: 73 cost=49.5801\n",
      "Epoch: 74 cost=44.2060\n",
      "Epoch: 75 cost=61.5019\n",
      "Epoch: 76 cost=41.8177\n",
      "Epoch: 77 cost=43.4051\n",
      "Epoch: 78 cost=41.4605\n",
      "Epoch: 79 cost=48.1909\n",
      "Epoch: 80 cost=57.3266\n",
      "Epoch: 81 cost=49.1338\n",
      "Epoch: 82 cost=54.2910\n",
      "Epoch: 83 cost=54.5366\n",
      "Epoch: 84 cost=50.3469\n",
      "Epoch: 85 cost=54.6070\n",
      "Epoch: 86 cost=57.3551\n",
      "Epoch: 87 cost=57.2253\n",
      "Epoch: 88 cost=53.5336\n",
      "Epoch: 89 cost=54.2445\n",
      "Epoch: 90 cost=38.5892\n",
      "Epoch: 91 cost=47.1108\n",
      "Epoch: 92 cost=51.0730\n",
      "Epoch: 93 cost=48.0153\n",
      "Epoch: 94 cost=55.3599\n",
      "Epoch: 95 cost=43.2955\n",
      "Epoch: 96 cost=48.1110\n",
      "Epoch: 97 cost=40.7270\n",
      "Epoch: 98 cost=47.8219\n",
      "Epoch: 99 cost=40.1684\n",
      "Epoch: 100 cost=45.6649\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "# Running the Session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    avg_cost = 0.0\n",
    "    no_of_batches = int(n_input/batch_size)\n",
    "    \n",
    "    for i in range(no_of_batches):\n",
    "        b1,b2 = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x:b1, y:b2})\n",
    "        avg_cost+=c/no_of_batches\n",
    "        \n",
    "    \n",
    "    print(\"Epoch: {} cost={:.4f}\".format(ep+1,avg_cost))\n",
    "    \n",
    "print('Training completed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8798\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "correct_predictions = tf.cast(correct_predictions, \"float\")\n",
    "accuracy = tf.reduce_mean(correct_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
