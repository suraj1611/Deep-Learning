{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing packages\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from pickle import dump,load\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and processing the file\n",
    "def read_file(path):\n",
    "    with open(path) as f:\n",
    "        stext = f.read().replace('\\n', ' ')\n",
    "    return stext\n",
    "\n",
    "text = read_file('med_conv.txt').lower()\n",
    "tokens = text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339958 70558\n"
     ]
    }
   ],
   "source": [
    "print(len(text),len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the text into 5+1 words to predict the next word\n",
    "train_len = 3+1\n",
    "text_seq = []\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_seq.append(seq)\n",
    "\n",
    "sequences={}\n",
    "cnt = 1\n",
    "for i in range(len(tokens)):\n",
    "    if tokens[i] not in sequences:\n",
    "        sequences[tokens[i]] = cnt\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_seq)\n",
    "sequences = tokenizer.texts_to_sequences(text_seq) \n",
    "\n",
    "#collecting info\n",
    "vocab_size = len(tokenizer.word_counts)\n",
    "n_seq = np.empty([len(sequences),train_len],dtype = 'int32')\n",
    "for i in range(len(sequences)):\n",
    "    n_seq[i] = sequences[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = n_seq[:,:-1]\n",
    "y_train = n_seq[:,-1]\n",
    "\n",
    "y_train = to_categorical(y_train,num_classes=vocab_size+1)\n",
    "seq_len = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    optimizer = optimizers.adam(lr=0.001)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Suraj\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size+1,seq_len)\n",
    "filepath=\"weights-improvement-{epoch:02d}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=1,save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train,y_train, epochs = 300, batch_size=128, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('word_pred_Model4.h5')\n",
    "model.load_weights('weights-improvement-299-bigger.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer,open('tokenizer_Model4','wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Enter exit_me to exit \n",
      "Enter the string: my knee is\n",
      "Output: my knee is hurting so much.\n",
      "Enter the string: i feel like\n",
      "Output: i feel like i can hardly\n",
      "Enter the string: i feel a\n",
      "Output: i feel a sharp pain in\n",
      "Enter the string: i have a\n",
      "Output: i have a pain that radiates\n",
      "Enter the string: my foot is\n",
      "Output: my foot is hard coming could\n",
      "Enter the string: i feel great\n",
      "Output: i feel great pain in my\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from pickle import load\n",
    "import numpy as np\n",
    "#model = load_model('word_pred_Model4.h5')\n",
    "tokenizer = load(open('tokenizer_Model4','rb'))\n",
    "seq_len = 3 \n",
    "def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len,truncating='pre')\n",
    "        pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
    "        (pred_word_ind)\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        input_text += ' '+pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return ' '.join(output_text)\n",
    "\n",
    "print('\\n\\n*** Enter exit_me to exit ')\n",
    "while True:\n",
    "    seed_text  = input('Enter the string: ')\n",
    "    if seed_text.lower() == 'exit_me':\n",
    "        break\n",
    "    else:\n",
    "        out = gen_text(model, tokenizer, seq_len=seq_len, seed_text=seed_text, num_gen_words=3)\n",
    "        print('Output: '+seed_text+' '+out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
